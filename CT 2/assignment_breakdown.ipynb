{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSC 580: Critical Thinking 2 - Predicting Future Sales\n",
    "In a nutshell, *sales_data_test.csv* and *sales_data_test.csv* contain data that will be used to train a neural network to predict how much money can be expected form the future sale of new video games. The .csv files were retrieved from one of [Toni Esteves repos](https://github.com/toniesteves/adam-geitgey-building-deep-learning-keras/tree/master/03). \n",
    "\n",
    "The columns in the data are defined as follows:\n",
    "- critic_rating : an average rating out of five stars\n",
    "- is_action : tells us if this was an action game\n",
    "- is_exclusive_to_us : tells us if we have an exclusiv deal to sell this game\n",
    "- is_portable : tells us if this game runs on a handheld video game system\n",
    "- is_role_playing : tells us if this is a role-playing game\n",
    "- is_sequel : tells us if this game was a sequel to an earlier video game and part of an ongoing series\n",
    "- is_sports : tells us if this was a sports game\n",
    "- suitable_for_kids : tells us if this game is appropriate for all ages\n",
    "- total_earning : tells us how much money the store has earned in total from selling the game to all customers\n",
    "- unit_price : tells us for how much a single copy of the game retailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras import layers \n",
    "from keras import activations\n",
    "from keras import optimizers\n",
    "from keras import losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare the Dataset\n",
    "The numerical data needs to be scaled for better network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: total_earnings values were scaled by multiplying by 0.0000042367 and adding -0.153415\n"
     ]
    }
   ],
   "source": [
    "# Load the training and testing data\n",
    "train_data = pd.read_csv(\"sales_data_training.csv\")\n",
    "test_data = pd.read_csv(\"sales_data_test.csv\")\n",
    "\n",
    "# Scale the data using sklearn\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "# Print out adjustment\n",
    "print(\"Note: total_earnings values were scaled by multiplying by {:.10f} and adding {:.6f}\".format(scaler.scale_[8], scaler.min_[8]))\n",
    "\n",
    "# Create new DataFrames\n",
    "df_train_scaled = pd.DataFrame(train_data_scaled, columns=train_data.columns.values)\n",
    "df_test_scaled = pd.DataFrame(test_data_scaled, columns=test_data.columns.values)\n",
    "\n",
    "# Save scaled data\n",
    "df_train_scaled.to_csv(\"sales_data_training_scaled.csv\", index=False)\n",
    "df_test_scaled.to_csv(\"sales_data_testing_scaled.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Coding the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "training_data_df = pd.read_csv(\"sales_data_training_scaled.csv\")\n",
    "\n",
    "X = training_data_df.drop('total_earnings', axis=1).values\n",
    "Y = training_data_df[['total_earnings']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = Sequential(\n",
    "    [\n",
    "        layers.Input((9,)),\n",
    "        layers.Dense(64, activation=activations.relu),\n",
    "        layers.Dense(32, activation=activations.relu),\n",
    "        layers.Dense(1, activation=activations.linear)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile('adam', losses.binary_crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 0s - loss: 0.5379\n",
      "Epoch 2/50\n",
      "100/100 - 0s - loss: 0.5378\n",
      "Epoch 3/50\n",
      "100/100 - 0s - loss: 0.5378\n",
      "Epoch 4/50\n",
      "100/100 - 0s - loss: 0.5377\n",
      "Epoch 5/50\n",
      "100/100 - 0s - loss: 0.5377\n",
      "Epoch 6/50\n",
      "100/100 - 0s - loss: 0.5377\n",
      "Epoch 7/50\n",
      "100/100 - 0s - loss: 0.5377\n",
      "Epoch 8/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 9/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 10/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 11/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 12/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 13/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 14/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 15/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 16/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 17/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 18/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 19/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 20/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 21/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 22/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 23/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 24/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 25/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 26/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 27/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 28/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 29/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 30/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 31/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 32/50\n",
      "100/100 - 0s - loss: 0.5379\n",
      "Epoch 33/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 34/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 35/50\n",
      "100/100 - 0s - loss: 0.5375\n",
      "Epoch 36/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 37/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 38/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 39/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 40/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 41/50\n",
      "100/100 - 0s - loss: 0.5377\n",
      "Epoch 42/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 43/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 44/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 45/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 46/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 47/50\n",
      "100/100 - 0s - loss: 0.5376\n",
      "Epoch 48/50\n",
      "100/100 - 0s - loss: 0.5378\n",
      "Epoch 49/50\n",
      "100/100 - 0s - loss: 0.5377\n",
      "Epoch 50/50\n",
      "100/100 - 0s - loss: 0.5377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc2b98887f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,batch_size = 10, epochs = 50, verbose=2, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "393fcab780e87c738780ceeb980b543ebdfd57cc9b80e4ffd28fcf595b13429f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('CSUG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
